{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# ResNet Transfer for NHTS Images"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This script practices the following things in PyTorch. \\\n",
    "1) data preprocessing with data loader. \\\n",
    "2) Simple but quick visualization tools. \\\n",
    "3) ResNet transfer learning for RGB images. \\\n",
    "Shenhao completed these tasks. He also found that the RGB satellite images look like random noise...\n",
    "\n",
    "Finding: \n",
    "ResNet with pretraining (finetuning the last layer vs. training the whole network). Performance: baseline + 1% \\\n",
    "ResNet with pretraining and allowing the training of the whole network. Severe overfitting in 20 epoches: baseline - 4%. Perfect in-sample performance, but bad out-of-sample performance. \\\n",
    "Naive CNN models for the RGB and BW images, the performance improve by about 2% (from 37% to 39%). \\\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "# ! pip3 list"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "from matplotlib import pyplot as plt\n",
    "import util\n",
    "from scipy import stats\n",
    "import copy\n",
    "\n",
    "# torch model\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "from torch.utils.data import TensorDataset, DataLoader\n",
    "import torchvision\n",
    "from torchvision import datasets, models, transforms\n",
    "from PIL import Image"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.metrics import accuracy_score\n",
    "from sklearn.metrics import confusion_matrix\n",
    "from sklearn.metrics import log_loss\n",
    "from sklearn.metrics import r2_score\n",
    "from sklearn.metrics import mean_squared_error\n",
    "from sklearn.preprocessing import PolynomialFeatures"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "import statsmodels.api as sm\n",
    "# import statsmodels"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "# ALWAYS choose devise first.\n",
    "# device = torch.device(\"cuda:0\" if torch.cuda.is_available() else \"cpu\")\n",
    "device = torch.device(\"cuda:0\" if torch.cuda.is_available() else \"cpu\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Helper Functions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "def initialize_data(image_type, output_var, output_type, input_var, BE_var, num_categories, size):\n",
    "    # outputs: randonmized training and testing sets for NHTS, BE, images, and y.\n",
    "    \n",
    "    ### read image array\n",
    "    if image_type == 'rgb':\n",
    "        image_array_ = np.load(\"data_shenhao/nhts/image_array_rgb_tract_large.npy\", mmap_mode='r')\n",
    "        image_array = image_array_[:size,]\n",
    "    elif image_type == 'bw':\n",
    "        image_array_ = np.load(\"data_shenhao/nhts/image_array_bw_tract_large.npy\", mmap_mode='r')\n",
    "        image_array = image_array_[:size,]        \n",
    "    elif image_type == 'merge':\n",
    "        bw_image_array_ = np.load(\"data_shenhao/nhts/image_array_bw_tract_large.npy\", mmap_mode='r')\n",
    "        rgb_image_array_ = np.load(\"data_shenhao/nhts/image_array_rgb_tract_large.npy\", mmap_mode='r')\n",
    "        bw_image_array = bw_image_array_[:size,]\n",
    "        rgb_image_array = rgb_image_array_[:size,]\n",
    "        image_array = np.concatenate([rgb_image_array, bw_image_array], axis=1)\n",
    "    \n",
    "    ### create output array\n",
    "    df_ = pd.read_csv(\"data_shenhao/nhts/df_merged_tract_large.csv\")\n",
    "    df = df_.iloc[:size,]\n",
    "    y_ = df[output_var].values \n",
    "    # cut y into categories for discrete variables\n",
    "    if output_type == 'continuous':\n",
    "        y = copy.deepcopy(y_)\n",
    "    elif output_type == 'discrete':\n",
    "        y = np.array(pd.qcut(y_, q = num_categories, labels=np.arange(num_categories))) \n",
    "    x = df[input_var]\n",
    "    BE = df[BE_var]\n",
    "            \n",
    "    ### randomization\n",
    "    shuffle_idx = np.arange(size)\n",
    "    np.random.seed(0) # important: don't change the seed number, unless the seed number across scripts are all changed.\n",
    "    np.random.shuffle(shuffle_idx)\n",
    "    train_ratio = 0.8\n",
    "\n",
    "    ###\n",
    "    # y\n",
    "    if output_type == 'discrete':\n",
    "        y_train = y[shuffle_idx[:int(train_ratio*size)]].astype(\"int\")\n",
    "        y_test = y[shuffle_idx[int(train_ratio*size):]].astype(\"int\")\n",
    "    elif output_type == 'continuous':\n",
    "        y_train = y[shuffle_idx[:int(train_ratio*size)]].astype(\"float32\")\n",
    "        y_test = y[shuffle_idx[int(train_ratio*size):]].astype(\"float32\")\n",
    "    # BE\n",
    "    BE_train = BE.values[shuffle_idx[:int(train_ratio*size)]].astype(\"float32\")\n",
    "    BE_test = BE.values[shuffle_idx[int(train_ratio*size):]].astype(\"float32\")        \n",
    "    # image array\n",
    "    x_train_images = image_array[shuffle_idx[:int(train_ratio*size)],].astype(\"float32\")\n",
    "    x_test_images = image_array[shuffle_idx[int(train_ratio*size):],].astype(\"float32\")\n",
    "    # NHTS\n",
    "    x_train = x.values[shuffle_idx[:int(train_ratio*size)]].astype(\"float32\")\n",
    "    x_test = x.values[shuffle_idx[int(train_ratio*size):]].astype(\"float32\")\n",
    "    \n",
    "    return y_train,y_test,BE_train,BE_test,x_train,x_test,x_train_images,x_test_images\n",
    "\n",
    "# # test \n",
    "# image_type = 'bw'\n",
    "# output_var = 'HHFAMINC_mean'\n",
    "# output_type = 'continuous'\n",
    "# input_var=['R_AGE_IMP_mean', 'HHSIZE_mean', 'HHFAMINC_mean', 'HBHTNRNT_mean', 'HBPPOPDN_mean', 'HBRESDN_mean', \n",
    "#            'R_SEX_IMP_2_mean', 'EDUC_2_mean', 'HH_RACE_2_mean', 'HOMEOWN_1_mean', 'HOMEOWN_2_mean',\n",
    "#            'HBHUR_R_mean', 'HBHUR_S_mean', 'HBHUR_T_mean','HBHUR_U_mean']\n",
    "# BE_var = ['density', 'diversity', 'design']\n",
    "# num_categories = 1 # (1) certain category values can cause errors. (2) when output_type = 'continuous', this value needs to be 1.\n",
    "# size = 10000 # size needs to be smaller than the max\n",
    "# # \n",
    "# y_train,y_test,BE_train,BE_test,x_train,x_test,x_train_images,x_test_images = \\\n",
    "#     initialize_data(image_type, output_var, output_type, input_var, BE_var, num_categories, size)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "size = 1000\n",
    "# Important trick: directly reading files from dropbox - Change the default \"dl=0\" to \"dl=1\"!\n",
    "# e.g. initial link: https://www.dropbox.com/s/sxakfluvdol2pwl/df_merged_tract_large.csv?dl=0\n",
    "df_ = pd.read_csv(\"https://www.dropbox.com/s/sxakfluvdol2pwl/df_merged_tract_large.csv?dl=1\")\n",
    "df = df_.iloc[:size,]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "ename": "FileNotFoundError",
     "evalue": "[Errno 2] No such file or directory: 'https://www.dropbox.com/s/ujssiypek3ur7n4/image_array_bw_tract_large.npy'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mFileNotFoundError\u001b[0m                         Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-15-bd2e2a14e2f5>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0mimage_array_\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mload\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"https://www.dropbox.com/s/ujssiypek3ur7n4/image_array_bw_tract_large.npy\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;32m~/anaconda3/lib/python3.7/site-packages/numpy/lib/npyio.py\u001b[0m in \u001b[0;36mload\u001b[0;34m(file, mmap_mode, allow_pickle, fix_imports, encoding)\u001b[0m\n\u001b[1;32m    426\u001b[0m         \u001b[0mown_fid\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;32mFalse\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    427\u001b[0m     \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 428\u001b[0;31m         \u001b[0mfid\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mopen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mos_fspath\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfile\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m\"rb\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    429\u001b[0m         \u001b[0mown_fid\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;32mTrue\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    430\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mFileNotFoundError\u001b[0m: [Errno 2] No such file or directory: 'https://www.dropbox.com/s/ujssiypek3ur7n4/image_array_bw_tract_large.npy'"
     ]
    }
   ],
   "source": [
    "image_array_ = np.load(\"https://www.dropbox.com/s/ujssiypek3ur7n4/image_array_bw_tract_large.npy\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "import dropbox"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "# try dropbox\n",
    "dbx = dropbox.Dropbox(\"sl.AdZzc_dGfmP76w5Jo2rILedhehyQLx0wy-tstsCGRgVrS1k-_szPoqVn1EQ0rgsQ178-aNV-pTvk2bViMaB2SfL25dy6Gya_nS6K2Nw1Dy-euKEDmbjKJVhx5lkHUhribdK_yg4\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "FullAccount(account_id='dbid:AACzRDQxkCMv7GDjiddxbH2YEBZZHGPwJi4', name=Name(given_name='shenhao', surname='Wang', familiar_name='shenhao', display_name='shenhao Wang', abbreviated_name='SW'), email='cjsyzwsh@gmail.com', email_verified=True, disabled=False, locale='en', referral_link='https://www.dropbox.com/referrals/AAB8SrgZtaMmkPZZfvPgywyvECi01CO0RmA?src=app9-8130080', is_paired=True, account_type=AccountType('pro', None), root_info=UserRootInfo(root_namespace_id='184231950', home_namespace_id='184231950'), profile_photo_url='https://dl-web.dropbox.com/account_photo/get/dbaphid%3AAAAH0tyx42fNkYkz35TnY8FA8-hrKhzBBms?size=128x128&vers=1510322698555', country='US', team=None, team_member_id=None)"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dbx.users_get_current_account()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ESSAYS\n",
      "BOOKS\n",
      "MPlus\n",
      "Books Temp for 2015\n",
      "My ESSAYS\n",
      "People\n",
      "Camera Uploads\n",
      "Endnote0\n",
      "16.0\n",
      "OneNote_backup\n",
      "2014_3_fall\n",
      "2014_4_winter\n",
      "2015_1_Spring\n",
      "2015_2_Summer\n",
      "2015_3_Fall\n",
      "2015_4_Winter\n",
      "2016_1_Spring\n",
      "2016_2_Summer\n",
      "2016_3_Fall\n",
      "2016_4_Winter\n",
      "2018_3_fall\n",
      "2018_3_fall_recording\n",
      "0_official_doc_shenhao\n",
      "0_summary_reading_class_topics\n",
      "2019_1_spring\n",
      "Pictures_Personal\n",
      "Pictures_WorkAndProject\n",
      "2018_1_Spring\n",
      "2019_3_fall\n",
      "2019_3_fall_records\n",
      "2020_1_spring\n",
      "3_career\n",
      "9_travel_process\n",
      "5_books_dailybooks\n",
      "5_books_textbook\n",
      "3_teaching\n",
      "2_personal\n",
      "4_networking_connections\n",
      "0_datasets\n",
      "3_paper_reviews\n",
      "0_English\n",
      "Ventilator_certificates_nyc\n",
      "2020_2_summer\n",
      "3_project_0_archive\n",
      "2017_3_fall_records\n",
      "2017_3_fall\n",
      "2017_1_spring\n",
      "2017_1_Spring_Records\n",
      "2018_1_spring_records\n",
      "2014_3_fall_Records\n",
      "2014_4_winter_records\n",
      "2015_3_Fall_Records\n",
      "2015_1_Spring_records\n",
      "2015_2_Summer_records\n",
      "2019_1_spring_records\n",
      "coding_latex\n",
      "coding_general\n",
      "coding_R\n",
      "2015 English\n",
      "2017_2_Summer\n",
      "2014 English\n",
      "2017_2_Summer Records\n",
      "2016_3_Fall_Records\n",
      "2016_1_Spring_Record\n",
      "2017_4_winter\n",
      "coding_Python\n",
      "._Books Temp for 2015\n",
      "._People\n",
      "._2014 Fall Courses\n",
      "._MIT_Uncertainty\n",
      "._2014-2015IAP\n",
      "._ESSAYS\n",
      "._2014 Listening Training Again_Damn It!!!!\n",
      "._MPlus\n",
      "._BOOKS\n",
      "._My ESSAYS\n",
      "._Accounts.txt\n",
      "._Endnote0\n",
      "._ (Shenhaos-MacBook-Pro.local's conflicted copy 2017-10-15)._Icon\r\n",
      "._ (Shenhaos-MacBook-Pro.local's conflicted copy 2017-11-10)._Icon\r\n",
      "._16.0\n",
      "._OneNote_backup\n",
      "._Icon\r\n"
     ]
    }
   ],
   "source": [
    "for entry in dbx.files_list_folder('').entries:\n",
    "    print(entry.name)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dbx.files_download_to_file()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "ename": "FileNotFoundError",
     "evalue": "[Errno 2] No such file or directory: 'https://www.dropbox.com/sh/37ctvcpqpnh0pfp/AABBxCo0rXfQjFqhiFJpzPNia?'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mFileNotFoundError\u001b[0m                         Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-19-aef17b9ef185>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0mos\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mchdir\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"https://www.dropbox.com/sh/37ctvcpqpnh0pfp/AABBxCo0rXfQjFqhiFJpzPNia?\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;31mFileNotFoundError\u001b[0m: [Errno 2] No such file or directory: 'https://www.dropbox.com/sh/37ctvcpqpnh0pfp/AABBxCo0rXfQjFqhiFJpzPNia?'"
     ]
    }
   ],
   "source": [
    "os.chdir(\"https://www.dropbox.com/sh/37ctvcpqpnh0pfp/AABBxCo0rXfQjFqhiFJpzPNia?\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pickle\n",
    "a = {\"tmp\": df}\n",
    "\n",
    "with open('tmp.pickle', 'wb') as handle:\n",
    "    pickle.dump(a, handle, protocol=pickle.HIGHEST_PROTOCOL)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\"https://www.dropbox.com/s/ujssiypek3ur7n4/image_array_bw_tract_large.npy?dl=0\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "ename": "UnicodeDecodeError",
     "evalue": "'utf-8' codec can't decode byte 0x93 in position 0: invalid start byte",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mUnicodeDecodeError\u001b[0m                        Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-14-6221483efba4>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0mpd\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mread_table\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"https://www.dropbox.com/s/ujssiypek3ur7n4/image_array_bw_tract_large.npy?dl=1\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;32m~/anaconda3/lib/python3.7/site-packages/pandas/io/parsers.py\u001b[0m in \u001b[0;36mparser_f\u001b[0;34m(filepath_or_buffer, sep, delimiter, header, names, index_col, usecols, squeeze, prefix, mangle_dupe_cols, dtype, engine, converters, true_values, false_values, skipinitialspace, skiprows, skipfooter, nrows, na_values, keep_default_na, na_filter, verbose, skip_blank_lines, parse_dates, infer_datetime_format, keep_date_col, date_parser, dayfirst, cache_dates, iterator, chunksize, compression, thousands, decimal, lineterminator, quotechar, quoting, doublequote, escapechar, comment, encoding, dialect, error_bad_lines, warn_bad_lines, delim_whitespace, low_memory, memory_map, float_precision)\u001b[0m\n\u001b[1;32m    683\u001b[0m         )\n\u001b[1;32m    684\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 685\u001b[0;31m         \u001b[0;32mreturn\u001b[0m \u001b[0m_read\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfilepath_or_buffer\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mkwds\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    686\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    687\u001b[0m     \u001b[0mparser_f\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m__name__\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mname\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/lib/python3.7/site-packages/pandas/io/parsers.py\u001b[0m in \u001b[0;36m_read\u001b[0;34m(filepath_or_buffer, kwds)\u001b[0m\n\u001b[1;32m    455\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    456\u001b[0m     \u001b[0;31m# Create the parser.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 457\u001b[0;31m     \u001b[0mparser\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mTextFileReader\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfp_or_buf\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwds\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    458\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    459\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0mchunksize\u001b[0m \u001b[0;32mor\u001b[0m \u001b[0miterator\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/lib/python3.7/site-packages/pandas/io/parsers.py\u001b[0m in \u001b[0;36m__init__\u001b[0;34m(self, f, engine, **kwds)\u001b[0m\n\u001b[1;32m    893\u001b[0m             \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0moptions\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m\"has_index_names\"\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mkwds\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m\"has_index_names\"\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    894\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 895\u001b[0;31m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_make_engine\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mengine\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    896\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    897\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mclose\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/lib/python3.7/site-packages/pandas/io/parsers.py\u001b[0m in \u001b[0;36m_make_engine\u001b[0;34m(self, engine)\u001b[0m\n\u001b[1;32m   1133\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0m_make_engine\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mengine\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m\"c\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1134\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mengine\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0;34m\"c\"\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1135\u001b[0;31m             \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_engine\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mCParserWrapper\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mf\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0moptions\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1136\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1137\u001b[0m             \u001b[0;32mif\u001b[0m \u001b[0mengine\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0;34m\"python\"\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/lib/python3.7/site-packages/pandas/io/parsers.py\u001b[0m in \u001b[0;36m__init__\u001b[0;34m(self, src, **kwds)\u001b[0m\n\u001b[1;32m   1915\u001b[0m         \u001b[0mkwds\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m\"usecols\"\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0musecols\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1916\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1917\u001b[0;31m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_reader\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mparsers\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mTextReader\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0msrc\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwds\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1918\u001b[0m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0munnamed_cols\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_reader\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0munnamed_cols\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1919\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32mpandas/_libs/parsers.pyx\u001b[0m in \u001b[0;36mpandas._libs.parsers.TextReader.__cinit__\u001b[0;34m()\u001b[0m\n",
      "\u001b[0;32mpandas/_libs/parsers.pyx\u001b[0m in \u001b[0;36mpandas._libs.parsers.TextReader._get_header\u001b[0;34m()\u001b[0m\n",
      "\u001b[0;31mUnicodeDecodeError\u001b[0m: 'utf-8' codec can't decode byte 0x93 in position 0: invalid start byte"
     ]
    }
   ],
   "source": [
    "pd.read_table(\"https://www.dropbox.com/s/ujssiypek3ur7n4/image_array_bw_tract_large.npy?dl=1\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "ename": "KeyError",
     "evalue": "\"['HBHTNRNT_mean', 'HBRESDN_mean', 'R_AGE_IMP_mean', 'HBPPOPDN_mean'] not in index\"",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyError\u001b[0m                                  Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-12-80973b507867>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m     10\u001b[0m \u001b[0msize\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;36m3000\u001b[0m \u001b[0;31m# size needs to be smaller than the max\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     11\u001b[0m \u001b[0;31m#\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 12\u001b[0;31m \u001b[0my_train\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0my_test\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mBE_train\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mBE_test\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mx_train\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mx_test\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mx_train_images\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mx_test_images\u001b[0m \u001b[0;34m=\u001b[0m     \u001b[0minitialize_data\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mimage_type\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0moutput_var\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0moutput_type\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0minput_var\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mBE_var\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mnum_categories\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0msize\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;32m<ipython-input-11-b2cd6f940210>\u001b[0m in \u001b[0;36minitialize_data\u001b[0;34m(image_type, output_var, output_type, input_var, BE_var, num_categories, size)\u001b[0m\n\u001b[1;32m     25\u001b[0m     \u001b[0;32melif\u001b[0m \u001b[0moutput_type\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0;34m'discrete'\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     26\u001b[0m         \u001b[0my\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0marray\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mpd\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mqcut\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0my_\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mq\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mnum_categories\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mlabels\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0marange\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mnum_categories\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 27\u001b[0;31m     \u001b[0mx\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mdf\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0minput_var\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     28\u001b[0m     \u001b[0mBE\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mdf\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mBE_var\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     29\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/home/shenhao/.local/lib/python3.6/site-packages/pandas/core/frame.py\u001b[0m in \u001b[0;36m__getitem__\u001b[0;34m(self, key)\u001b[0m\n\u001b[1;32m   2804\u001b[0m             \u001b[0;32mif\u001b[0m \u001b[0mis_iterator\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mkey\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2805\u001b[0m                 \u001b[0mkey\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mlist\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mkey\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 2806\u001b[0;31m             \u001b[0mindexer\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mloc\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_get_listlike_indexer\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mkey\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0maxis\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mraise_missing\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mTrue\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   2807\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2808\u001b[0m         \u001b[0;31m# take() does not accept boolean indexers\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/home/shenhao/.local/lib/python3.6/site-packages/pandas/core/indexing.py\u001b[0m in \u001b[0;36m_get_listlike_indexer\u001b[0;34m(self, key, axis, raise_missing)\u001b[0m\n\u001b[1;32m   1551\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1552\u001b[0m         self._validate_read_indexer(\n\u001b[0;32m-> 1553\u001b[0;31m             \u001b[0mkeyarr\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mindexer\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mo\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_get_axis_number\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0maxis\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mraise_missing\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mraise_missing\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1554\u001b[0m         )\n\u001b[1;32m   1555\u001b[0m         \u001b[0;32mreturn\u001b[0m \u001b[0mkeyarr\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mindexer\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/home/shenhao/.local/lib/python3.6/site-packages/pandas/core/indexing.py\u001b[0m in \u001b[0;36m_validate_read_indexer\u001b[0;34m(self, key, indexer, axis, raise_missing)\u001b[0m\n\u001b[1;32m   1644\u001b[0m             \u001b[0;32mif\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mname\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0;34m\"loc\"\u001b[0m \u001b[0;32mand\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0mraise_missing\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1645\u001b[0m                 \u001b[0mnot_found\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mlist\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mset\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mkey\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m-\u001b[0m \u001b[0mset\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0max\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1646\u001b[0;31m                 \u001b[0;32mraise\u001b[0m \u001b[0mKeyError\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34mf\"{not_found} not in index\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1647\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1648\u001b[0m             \u001b[0;31m# we skip the warning on Categorical/Interval\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mKeyError\u001b[0m: \"['HBHTNRNT_mean', 'HBRESDN_mean', 'R_AGE_IMP_mean', 'HBPPOPDN_mean'] not in index\""
     ]
    }
   ],
   "source": [
    "# test \n",
    "image_type = 'bw'\n",
    "output_var = 'HHFAMINC_mean'\n",
    "output_type = 'continuous'\n",
    "input_var=['R_AGE_IMP_mean', 'HHSIZE_mean', 'HHFAMINC_mean', 'HBHTNRNT_mean', 'HBPPOPDN_mean', 'HBRESDN_mean', \n",
    "           'R_SEX_IMP_2_mean', 'EDUC_2_mean', 'HH_RACE_2_mean', 'HOMEOWN_1_mean', 'HOMEOWN_2_mean',\n",
    "           'HBHUR_R_mean', 'HBHUR_S_mean', 'HBHUR_T_mean','HBHUR_U_mean']\n",
    "BE_var = ['density', 'diversity', 'design']\n",
    "num_categories = 1 # (1) certain category values can cause errors. (2) when output_type = 'continuous', this value needs to be 1.\n",
    "size = 3000 # size needs to be smaller than the max\n",
    "# \n",
    "y_train,y_test,BE_train,BE_test,x_train,x_test,x_train_images,x_test_images = \\\n",
    "    initialize_data(image_type, output_var, output_type, input_var, BE_var, num_categories, size)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# read data; It takes 20 minutes without mmap_mode(!!!).\n",
    "# this mmap_mode is super useful.\n",
    "x_train_images_ = np.load(\"data_shenhao/nhts/image_array_rgb_tract_large.npy\", mmap_mode = 'r')\n",
    "\n",
    "\n",
    "# x_train_images_ = np.load(\"data_shenhao/nhts/x_train_rgb_tract_large.npy\", mmap_mode = 'r')\n",
    "# x_test_images_ = np.load(\"data_shenhao/nhts/x_test_rgb_tract_large.npy\", mmap_mode = 'r')\n",
    "\n",
    "# x_train_images_ = np.load(\"data_shenhao/nhts/x_train_bw_images.npy\", mmap_mode = 'r')\n",
    "# x_test_images_ = np.load(\"data_shenhao/nhts/x_test_bw_images.npy\", mmap_mode = 'r')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "n = x_train_images_.shape[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(n)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# read y.\n",
    "y_train_ = np.load(\"data_shenhao/nhts/y_train.npy\")\n",
    "y_test_ = np.load(\"data_shenhao/nhts/y_test.npy\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# print(\"The sample size of training set is: \", x_train_nhts.shape[0])\n",
    "# print(\"The sample size of testing set is: \", x_test_nhts.shape[0])\n",
    "print(\"Training image shape: \", x_train_images_.shape)\n",
    "print(\"Testing image shape: \", x_test_images_.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "device = torch.device(\"cuda:0\" if torch.cuda.is_available() else \"cpu\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Data Preparation "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# you need to use only a subset here. The full set is REALLY SLOW for debugging...\n",
    "size = 2000\n",
    "x_train_images = x_train_images_[:size, :, :, :]\n",
    "x_test_images = x_test_images_[:size, :, :, :]\n",
    "y_train = y_train_[:size]\n",
    "y_test = y_test_[:size]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "y_train[y_train > 2] = 3\n",
    "y_test[y_test > 2] = 3"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "y_train = y_train.astype('int')\n",
    "y_test = y_test.astype('int')\n",
    "print(np.unique(y_train, return_counts=True)[1]/len(y_train))\n",
    "print(np.unique(y_test, return_counts=True)[1]/len(y_test))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Transform & Visualization\n",
    "Two ways to transform. \\\n",
    "1) Potentially use the torchvision.transforms. However, then you have to iteratre over each image with PIL Image. It can be very slow. \n",
    "2) Customize the transformation by yourself in numpy...\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# specify data type. \n",
    "x_train_images=x_train_images.astype(\"float32\")\n",
    "x_test_images=x_test_images.astype(\"float32\")\n",
    "y_train=y_train.astype(\"int\")\n",
    "y_test=y_test.astype(\"int\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# transform.\n",
    "# normalize to [0,1]\n",
    "x_train_images_norm = x_train_images/255\n",
    "x_test_images_norm = x_test_images/255\n",
    "\n",
    "# to torch\n",
    "x_train_torch = torch.from_numpy(x_train_images_norm)\n",
    "x_test_torch = torch.from_numpy(x_test_images_norm)\n",
    "y_train_torch = torch.from_numpy(y_train)\n",
    "y_test_torch = torch.from_numpy(y_test)\n",
    "\n",
    "print(x_train_torch.size())\n",
    "print(x_test_torch.size())\n",
    "print(y_train_torch.size())\n",
    "print(y_test_torch.size())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# use data loader: train and test. \n",
    "train_ds = TensorDataset(x_train_torch, y_train_torch)\n",
    "batch_size = 200\n",
    "train_dl = DataLoader(train_ds, batch_size, shuffle = True)\n",
    "\n",
    "test_ds = TensorDataset(x_test_torch, y_test_torch)\n",
    "batch_size = 200\n",
    "test_dl = DataLoader(test_ds, batch_size, shuffle = True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "# visualize with torchvision.\n",
    "images_, labels_ = iter(train_dl).next()\n",
    "images = images_[:5,] # visualize five images\n",
    "labels = labels_[:5] # visualize five images\n",
    "\n",
    "def imshow(img):\n",
    "#     img = img * 255.0     # unnormalize\n",
    "    npimg = img.numpy()\n",
    "    plt.figure(figsize = (15,3))\n",
    "    plt.imshow(np.transpose(npimg, (1, 2, 0)))\n",
    "    plt.show()\n",
    "    \n",
    "imshow(torchvision.utils.make_grid(images))\n",
    "print(labels.numpy())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 1. Use naive CNN model\n",
    "class Net(nn.Module):\n",
    "    # sw: again. It is critical to understand the dimension transformation.\n",
    "    def __init__(self):\n",
    "        super(Net, self).__init__()\n",
    "        self.conv1 = nn.Conv2d(3, 6, 5) # sw: change the input channel for data set.\n",
    "        self.pool = nn.MaxPool2d(2, 2)\n",
    "        self.conv2 = nn.Conv2d(6, 16, 5)\n",
    "        self.fc1 = nn.Linear(16 * 47 * 47, 120)\n",
    "        self.fc2 = nn.Linear(120, 84)\n",
    "        self.fc3 = nn.Linear(84, 4)\n",
    "\n",
    "    def forward(self, x):\n",
    "        x = self.pool(F.relu(self.conv1(x)))\n",
    "        x = self.pool(F.relu(self.conv2(x)))\n",
    "        x = x.view(-1, 16 * 47 * 47)\n",
    "        x = F.relu(self.fc1(x))\n",
    "        x = F.relu(self.fc2(x))\n",
    "        x = self.fc3(x)\n",
    "        return x\n",
    "\n",
    "# initialize\n",
    "net = Net().float().to(device)\n",
    "\n",
    "# # test\n",
    "# images, labels = iter(train_dl).next()\n",
    "# output = net(images)\n",
    "# print(output.size())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 2. Use ResNet.\n",
    "model_ft = models.resnet18(pretrained=False)\n",
    "for param in model_ft.parameters():\n",
    "    param.requires_grad = True # Shenhao might change it to True. Train the full set.\n",
    "\n",
    "# The following line allows us to edit the input channels.\n",
    "# model_ft.conv1 = nn.Conv2d(4, 64, kernel_size=(7, 7), stride=(2, 2), padding=(3, 3), bias=False)    \n",
    "num_ftrs = model_ft.fc.in_features\n",
    "model_ft.fc = nn.Linear(num_ftrs, 4)\n",
    "net = model_ft.to(device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch.optim as optim\n",
    "\n",
    "criterion = nn.CrossEntropyLoss()\n",
    "optimizer = optim.SGD(net.parameters(), lr=0.001, momentum=0.9)\n",
    "n_epoch = 100"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "for epoch in range(n_epoch):# loop over the dataset multiple times\n",
    "    # sw: learn the way of printing out the total loss for each batch.\n",
    "    running_loss_train = 0.0\n",
    "    running_loss_test = 0.0\n",
    "    correct_train = 0\n",
    "    total_train = 0\n",
    "    correct_test = 0\n",
    "    total_test = 0\n",
    "    \n",
    "    # training    \n",
    "    for inputs, labels in train_dl:\n",
    "        # to device\n",
    "        inputs = inputs.to(device)\n",
    "        labels = labels.to(device)\n",
    "\n",
    "        # forward + backward\n",
    "        outputs = net(inputs)\n",
    "        loss = criterion(outputs, labels)\n",
    "        loss.backward()\n",
    "        \n",
    "        # evaluate prediction\n",
    "        _, predicted = torch.max(outputs.data, 1)\n",
    "        total_train += labels.size(0)\n",
    "        correct_train += (predicted == labels).sum().item()\n",
    "        \n",
    "        # optimize\n",
    "        optimizer.step()\n",
    "        optimizer.zero_grad()\n",
    "        \n",
    "        # statistics\n",
    "        running_loss_train += loss.item()\n",
    "        \n",
    "    # testing\n",
    "    for inputs, labels in test_dl:\n",
    "        # to device\n",
    "        inputs = inputs.to(device)\n",
    "        labels = labels.to(device)\n",
    "        outputs = net(inputs)\n",
    "        loss = criterion(outputs, labels)\n",
    "        running_loss_test += loss.item()\n",
    "        \n",
    "        # evaluate prediction\n",
    "        _, predicted = torch.max(outputs.data, 1)\n",
    "        total_test += labels.size(0)\n",
    "        correct_test += (predicted == labels).sum().item()\n",
    "        \n",
    "    print(\"Epoch {}: Training Loss {}; Testing Loss {}\".format(epoch, running_loss_train, running_loss_test))\n",
    "    print(\"Epoch {}: Training Accuracy {}; Testing Accuracy {}\".format(epoch, correct_train/total_train, correct_test/total_test))\n",
    "\n",
    "#         if i % 2000 == 1999:    # print every 2000 mini-batches\n",
    "#             print('[%d, %5d] loss: %.3f' %\n",
    "#                   (epoch + 1, i + 1, running_loss / 2000))\n",
    "#             running_loss = 0.0\n",
    "# print('Finished Training')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
