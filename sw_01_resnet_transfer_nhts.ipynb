{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# ResNet Transfer for NHTS Images"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This script practices the following things in PyTorch. \\\n",
    "1) data preprocessing with data loader. \\\n",
    "2) Simple but quick visualization tools. \\\n",
    "3) ResNet transfer learning for RGB images. \\\n",
    "Shenhao completed these tasks. He also found that the RGB satellite images look like random noise...\n",
    "\n",
    "Finding: \n",
    "ResNet with pretraining (finetuning the last layer vs. training the whole network). Performance: baseline + 1% \\\n",
    "ResNet with pretraining and allowing the training of the whole network. Severe overfitting in 20 epoches: baseline - 4%. Perfect in-sample performance, but bad out-of-sample performance. \\\n",
    "Naive CNN models for the RGB and BW images, the performance improve by about 2% (from 37% to 39%). \\\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[31mDEPRECATION: The default format will switch to columns in the future. You can use --format=(legacy|columns) (or define a format=(legacy|columns) in your pip.conf under the [list] section) to disable this warning.\u001b[0m\n",
      "absl-py (0.9.0)\n",
      "appdirs (1.4.3)\n",
      "apt-clone (0.2.1)\n",
      "apturl (0.5.2)\n",
      "asn1crypto (0.24.0)\n",
      "astor (0.8.1)\n",
      "attrs (17.4.0)\n",
      "beautifulsoup4 (4.6.0)\n",
      "bleach (2.1.2)\n",
      "Brlapi (0.6.6)\n",
      "caffe (1.0.0)\n",
      "certifi (2018.1.18)\n",
      "cffi (1.11.5)\n",
      "chardet (3.0.4)\n",
      "command-not-found (0.3)\n",
      "cryptography (2.1.4)\n",
      "cupshelpers (1.0)\n",
      "cycler (0.10.0)\n",
      "decorator (4.1.2)\n",
      "defer (1.0.6)\n",
      "distro-info (0.18ubuntu0.18.04.1)\n",
      "entrypoints (0.2.3.post1)\n",
      "flake8 (3.5.0)\n",
      "future (0.15.2)\n",
      "gast (0.3.3)\n",
      "google-pasta (0.2.0)\n",
      "grpcio (1.24.0)\n",
      "h5py (2.7.1)\n",
      "html5lib (0.999999999)\n",
      "httplib2 (0.9.2)\n",
      "idna (2.6)\n",
      "ipykernel (4.8.2)\n",
      "ipython (5.5.0)\n",
      "ipython-genutils (0.2.0)\n",
      "ipywidgets (6.0.0)\n",
      "Jinja2 (2.10)\n",
      "joblib (0.11)\n",
      "jsonschema (2.6.0)\n",
      "jupyter-client (5.2.2)\n",
      "jupyter-console (5.2.0)\n",
      "jupyter-core (4.4.0)\n",
      "Keras (2.3.1)\n",
      "Keras-Applications (1.0.8)\n",
      "Keras-Preprocessing (1.1.0)\n",
      "keyring (10.6.0)\n",
      "keyrings.alt (3.0)\n",
      "language-selector (0.1)\n",
      "launchpadlib (1.10.6)\n",
      "lazr.restfulclient (0.13.5)\n",
      "lazr.uri (1.0.3)\n",
      "leveldb (0.1)\n",
      "louis (3.5.0)\n",
      "lxml (4.2.1)\n",
      "macaroonbakery (1.1.3)\n",
      "Mako (1.0.7)\n",
      "Markdown (2.6.9)\n",
      "MarkupSafe (1.0)\n",
      "matplotlib (2.1.1)\n",
      "mccabe (0.6.1)\n",
      "mistune (0.8.3)\n",
      "nbconvert (5.3.1)\n",
      "nbformat (4.4.0)\n",
      "netifaces (0.10.4)\n",
      "networkx (1.11)\n",
      "nose (1.3.7)\n",
      "nose-parameterized (0.3.4)\n",
      "notebook (5.2.2)\n",
      "numexpr (2.6.4)\n",
      "numpy (1.19.0)\n",
      "nvidia-ml-py (7.352.0)\n",
      "oauth (1.0.1)\n",
      "olefile (0.45.1)\n",
      "PAM (0.4.2)\n",
      "pandas (1.0.5)\n",
      "pandocfilters (1.4.2)\n",
      "patsy (0.5.1)\n",
      "pexpect (4.2.1)\n",
      "pickleshare (0.7.4)\n",
      "Pillow (5.1.0)\n",
      "pip (9.0.1)\n",
      "pluggy (0.6.0)\n",
      "ply (3.11)\n",
      "prompt-toolkit (1.0.15)\n",
      "protobuf (3.8.0)\n",
      "py (1.5.2)\n",
      "pycairo (1.16.2)\n",
      "pycodestyle (2.3.1)\n",
      "pycparser (2.18)\n",
      "pycrypto (2.6.1)\n",
      "pycuda (2019.1.2)\n",
      "pycups (1.9.73)\n",
      "pydot (1.2.3)\n",
      "pyflakes (1.6.0)\n",
      "Pygments (2.2.0)\n",
      "pygobject (3.26.1)\n",
      "pygpu (0.7.6)\n",
      "PyICU (1.9.8)\n",
      "pyinotify (0.9.6)\n",
      "pymacaroons (0.13.0)\n",
      "PyNaCl (1.1.2)\n",
      "pyOpenSSL (17.5.0)\n",
      "pyparsing (2.2.0)\n",
      "pyRFC3339 (1.0)\n",
      "pytest (3.3.2)\n",
      "python-apt (1.6.5+ubuntu0.3)\n",
      "python-dateutil (2.8.1)\n",
      "python-debian (0.1.32)\n",
      "pytools (2017.6)\n",
      "pytz (2020.1)\n",
      "PyWavelets (0.5.1)\n",
      "pyxdg (0.25)\n",
      "PyYAML (3.12)\n",
      "pyzmq (16.0.2)\n",
      "reportlab (3.4.0)\n",
      "requests (2.18.4)\n",
      "requests-unixsocket (0.1.5)\n",
      "scikit-cuda (0.5.3)\n",
      "scikit-image (0.13.1)\n",
      "scikit-learn (0.19.1)\n",
      "scipy (1.5.1)\n",
      "screen-resolution-extra (0.0.0)\n",
      "SecretStorage (2.3.1)\n",
      "setuptools (39.0.1)\n",
      "simplegeneric (0.8.1)\n",
      "simplejson (3.13.2)\n",
      "six (1.15.0)\n",
      "statsmodels (0.11.1)\n",
      "system-service (0.3)\n",
      "systemd-python (234)\n",
      "tables (3.4.2)\n",
      "tensorboard (1.15.0)\n",
      "tensorflow-estimator (1.15.1)\n",
      "tensorflow-gpu (1.15.3)\n",
      "tensorflow-serving-api (1.15.0)\n",
      "termcolor (1.1.0)\n",
      "terminado (0.7)\n",
      "testpath (0.3.1)\n",
      "Theano (1.0.4)\n",
      "torch (1.4.0)\n",
      "torchvision (0.5.0)\n",
      "tornado (4.5.3)\n",
      "traitlets (4.3.2)\n",
      "ubuntu-drivers-common (0.0.0)\n",
      "ufw (0.36)\n",
      "unattended-upgrades (0.1)\n",
      "urllib3 (1.22)\n",
      "usb-creator (0.3.3)\n",
      "virtualenv (15.1.0)\n",
      "wadllib (1.3.2)\n",
      "wcwidth (0.1.7)\n",
      "webencodings (0.5)\n",
      "Werkzeug (0.14.1)\n",
      "wheel (0.30.0)\n",
      "wrapt (1.9.0)\n",
      "xkit (0.0.0)\n",
      "zope.interface (4.3.2)\n"
     ]
    }
   ],
   "source": [
    "# ! pip3 list"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "from matplotlib import pyplot as plt\n",
    "import util\n",
    "from scipy import stats\n",
    "import copy\n",
    "\n",
    "# torch model\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "from torch.utils.data import TensorDataset, DataLoader\n",
    "import torchvision\n",
    "from torchvision import datasets, models, transforms\n",
    "from PIL import Image"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.metrics import accuracy_score\n",
    "from sklearn.metrics import confusion_matrix\n",
    "from sklearn.metrics import log_loss\n",
    "from sklearn.metrics import r2_score\n",
    "from sklearn.metrics import mean_squared_error\n",
    "from sklearn.preprocessing import PolynomialFeatures"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "import statsmodels.api as sm\n",
    "# import statsmodels"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "# ALWAYS choose devise first.\n",
    "# device = torch.device(\"cuda:0\" if torch.cuda.is_available() else \"cpu\")\n",
    "device = torch.device(\"cuda:0\" if torch.cuda.is_available() else \"cpu\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Helper Functions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "def initialize_data(image_type, output_var, output_type, input_var, BE_var, num_categories, size):\n",
    "    # outputs: randonmized training and testing sets for NHTS, BE, images, and y.\n",
    "    \n",
    "    ### read image array\n",
    "    if image_type == 'rgb':\n",
    "        image_array_ = np.load(\"data_shenhao/nhts/image_array_rgb_tract_large.npy\", mmap_mode='r')\n",
    "        image_array = image_array_[:size,]\n",
    "    elif image_type == 'bw':\n",
    "        image_array_ = np.load(\"data_shenhao/nhts/image_array_bw_tract_large.npy\", mmap_mode='r')\n",
    "        image_array = image_array_[:size,]        \n",
    "    elif image_type == 'merge':\n",
    "        bw_image_array_ = np.load(\"data_shenhao/nhts/image_array_bw_tract_large.npy\", mmap_mode='r')\n",
    "        rgb_image_array_ = np.load(\"data_shenhao/nhts/image_array_rgb_tract_large.npy\", mmap_mode='r')\n",
    "        bw_image_array = bw_image_array_[:size,]\n",
    "        rgb_image_array = rgb_image_array_[:size,]\n",
    "        image_array = np.concatenate([rgb_image_array, bw_image_array], axis=1)\n",
    "    \n",
    "    ### create output array\n",
    "    df_ = pd.read_csv(\"data_shenhao/nhts/df_merged_tract_large.csv\")\n",
    "    df = df_.iloc[:size,]\n",
    "    y_ = df[output_var].values \n",
    "    # cut y into categories for discrete variables\n",
    "    if output_type == 'continuous':\n",
    "        y = copy.deepcopy(y_)\n",
    "    elif output_type == 'discrete':\n",
    "        y = np.array(pd.qcut(y_, q = num_categories, labels=np.arange(num_categories))) \n",
    "    x = df[input_var]\n",
    "    BE = df[BE_var]\n",
    "            \n",
    "    ### randomization\n",
    "    shuffle_idx = np.arange(size)\n",
    "    np.random.seed(0) # important: don't change the seed number, unless the seed number across scripts are all changed.\n",
    "    np.random.shuffle(shuffle_idx)\n",
    "    train_ratio = 0.8\n",
    "\n",
    "    ###\n",
    "    # y\n",
    "    if output_type == 'discrete':\n",
    "        y_train = y[shuffle_idx[:int(train_ratio*size)]].astype(\"int\")\n",
    "        y_test = y[shuffle_idx[int(train_ratio*size):]].astype(\"int\")\n",
    "    elif output_type == 'continuous':\n",
    "        y_train = y[shuffle_idx[:int(train_ratio*size)]].astype(\"float32\")\n",
    "        y_test = y[shuffle_idx[int(train_ratio*size):]].astype(\"float32\")\n",
    "    # BE\n",
    "    BE_train = BE.values[shuffle_idx[:int(train_ratio*size)]].astype(\"float32\")\n",
    "    BE_test = BE.values[shuffle_idx[int(train_ratio*size):]].astype(\"float32\")        \n",
    "    # image array\n",
    "    x_train_images = image_array[shuffle_idx[:int(train_ratio*size)],].astype(\"float32\")\n",
    "    x_test_images = image_array[shuffle_idx[int(train_ratio*size):],].astype(\"float32\")\n",
    "    # NHTS\n",
    "    x_train = x.values[shuffle_idx[:int(train_ratio*size)]].astype(\"float32\")\n",
    "    x_test = x.values[shuffle_idx[int(train_ratio*size):]].astype(\"float32\")\n",
    "    \n",
    "    return y_train,y_test,BE_train,BE_test,x_train,x_test,x_train_images,x_test_images\n",
    "\n",
    "# # test \n",
    "# image_type = 'bw'\n",
    "# output_var = 'HHFAMINC_mean'\n",
    "# output_type = 'continuous'\n",
    "# input_var=['R_AGE_IMP_mean', 'HHSIZE_mean', 'HHFAMINC_mean', 'HBHTNRNT_mean', 'HBPPOPDN_mean', 'HBRESDN_mean', \n",
    "#            'R_SEX_IMP_2_mean', 'EDUC_2_mean', 'HH_RACE_2_mean', 'HOMEOWN_1_mean', 'HOMEOWN_2_mean',\n",
    "#            'HBHUR_R_mean', 'HBHUR_S_mean', 'HBHUR_T_mean','HBHUR_U_mean']\n",
    "# BE_var = ['density', 'diversity', 'design']\n",
    "# num_categories = 1 # (1) certain category values can cause errors. (2) when output_type = 'continuous', this value needs to be 1.\n",
    "# size = 10000 # size needs to be smaller than the max\n",
    "# # \n",
    "# y_train,y_test,BE_train,BE_test,x_train,x_test,x_train_images,x_test_images = \\\n",
    "#     initialize_data(image_type, output_var, output_type, input_var, BE_var, num_categories, size)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    " df_ = pd.read_csv(\"data_shenhao/nhts/df_merged_tract_large.csv\")\n",
    "    df = df_.iloc[:size,]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "ename": "KeyError",
     "evalue": "\"['HBHTNRNT_mean', 'HBRESDN_mean', 'R_AGE_IMP_mean', 'HBPPOPDN_mean'] not in index\"",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyError\u001b[0m                                  Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-12-80973b507867>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m     10\u001b[0m \u001b[0msize\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;36m3000\u001b[0m \u001b[0;31m# size needs to be smaller than the max\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     11\u001b[0m \u001b[0;31m#\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 12\u001b[0;31m \u001b[0my_train\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0my_test\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mBE_train\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mBE_test\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mx_train\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mx_test\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mx_train_images\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mx_test_images\u001b[0m \u001b[0;34m=\u001b[0m     \u001b[0minitialize_data\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mimage_type\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0moutput_var\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0moutput_type\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0minput_var\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mBE_var\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mnum_categories\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0msize\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;32m<ipython-input-11-b2cd6f940210>\u001b[0m in \u001b[0;36minitialize_data\u001b[0;34m(image_type, output_var, output_type, input_var, BE_var, num_categories, size)\u001b[0m\n\u001b[1;32m     25\u001b[0m     \u001b[0;32melif\u001b[0m \u001b[0moutput_type\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0;34m'discrete'\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     26\u001b[0m         \u001b[0my\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0marray\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mpd\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mqcut\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0my_\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mq\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mnum_categories\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mlabels\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0marange\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mnum_categories\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 27\u001b[0;31m     \u001b[0mx\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mdf\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0minput_var\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     28\u001b[0m     \u001b[0mBE\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mdf\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mBE_var\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     29\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/home/shenhao/.local/lib/python3.6/site-packages/pandas/core/frame.py\u001b[0m in \u001b[0;36m__getitem__\u001b[0;34m(self, key)\u001b[0m\n\u001b[1;32m   2804\u001b[0m             \u001b[0;32mif\u001b[0m \u001b[0mis_iterator\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mkey\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2805\u001b[0m                 \u001b[0mkey\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mlist\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mkey\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 2806\u001b[0;31m             \u001b[0mindexer\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mloc\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_get_listlike_indexer\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mkey\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0maxis\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mraise_missing\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mTrue\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   2807\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2808\u001b[0m         \u001b[0;31m# take() does not accept boolean indexers\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/home/shenhao/.local/lib/python3.6/site-packages/pandas/core/indexing.py\u001b[0m in \u001b[0;36m_get_listlike_indexer\u001b[0;34m(self, key, axis, raise_missing)\u001b[0m\n\u001b[1;32m   1551\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1552\u001b[0m         self._validate_read_indexer(\n\u001b[0;32m-> 1553\u001b[0;31m             \u001b[0mkeyarr\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mindexer\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mo\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_get_axis_number\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0maxis\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mraise_missing\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mraise_missing\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1554\u001b[0m         )\n\u001b[1;32m   1555\u001b[0m         \u001b[0;32mreturn\u001b[0m \u001b[0mkeyarr\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mindexer\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/home/shenhao/.local/lib/python3.6/site-packages/pandas/core/indexing.py\u001b[0m in \u001b[0;36m_validate_read_indexer\u001b[0;34m(self, key, indexer, axis, raise_missing)\u001b[0m\n\u001b[1;32m   1644\u001b[0m             \u001b[0;32mif\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mname\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0;34m\"loc\"\u001b[0m \u001b[0;32mand\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0mraise_missing\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1645\u001b[0m                 \u001b[0mnot_found\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mlist\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mset\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mkey\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m-\u001b[0m \u001b[0mset\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0max\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1646\u001b[0;31m                 \u001b[0;32mraise\u001b[0m \u001b[0mKeyError\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34mf\"{not_found} not in index\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1647\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1648\u001b[0m             \u001b[0;31m# we skip the warning on Categorical/Interval\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mKeyError\u001b[0m: \"['HBHTNRNT_mean', 'HBRESDN_mean', 'R_AGE_IMP_mean', 'HBPPOPDN_mean'] not in index\""
     ]
    }
   ],
   "source": [
    "# test \n",
    "image_type = 'bw'\n",
    "output_var = 'HHFAMINC_mean'\n",
    "output_type = 'continuous'\n",
    "input_var=['R_AGE_IMP_mean', 'HHSIZE_mean', 'HHFAMINC_mean', 'HBHTNRNT_mean', 'HBPPOPDN_mean', 'HBRESDN_mean', \n",
    "           'R_SEX_IMP_2_mean', 'EDUC_2_mean', 'HH_RACE_2_mean', 'HOMEOWN_1_mean', 'HOMEOWN_2_mean',\n",
    "           'HBHUR_R_mean', 'HBHUR_S_mean', 'HBHUR_T_mean','HBHUR_U_mean']\n",
    "BE_var = ['density', 'diversity', 'design']\n",
    "num_categories = 1 # (1) certain category values can cause errors. (2) when output_type = 'continuous', this value needs to be 1.\n",
    "size = 3000 # size needs to be smaller than the max\n",
    "# \n",
    "y_train,y_test,BE_train,BE_test,x_train,x_test,x_train_images,x_test_images = \\\n",
    "    initialize_data(image_type, output_var, output_type, input_var, BE_var, num_categories, size)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# read data; It takes 20 minutes without mmap_mode(!!!).\n",
    "# this mmap_mode is super useful.\n",
    "x_train_images_ = np.load(\"data_shenhao/nhts/image_array_rgb_tract_large.npy\", mmap_mode = 'r')\n",
    "\n",
    "\n",
    "# x_train_images_ = np.load(\"data_shenhao/nhts/x_train_rgb_tract_large.npy\", mmap_mode = 'r')\n",
    "# x_test_images_ = np.load(\"data_shenhao/nhts/x_test_rgb_tract_large.npy\", mmap_mode = 'r')\n",
    "\n",
    "# x_train_images_ = np.load(\"data_shenhao/nhts/x_train_bw_images.npy\", mmap_mode = 'r')\n",
    "# x_test_images_ = np.load(\"data_shenhao/nhts/x_test_bw_images.npy\", mmap_mode = 'r')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "n = x_train_images_.shape[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(n)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# read y.\n",
    "y_train_ = np.load(\"data_shenhao/nhts/y_train.npy\")\n",
    "y_test_ = np.load(\"data_shenhao/nhts/y_test.npy\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# print(\"The sample size of training set is: \", x_train_nhts.shape[0])\n",
    "# print(\"The sample size of testing set is: \", x_test_nhts.shape[0])\n",
    "print(\"Training image shape: \", x_train_images_.shape)\n",
    "print(\"Testing image shape: \", x_test_images_.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "device = torch.device(\"cuda:0\" if torch.cuda.is_available() else \"cpu\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Data Preparation "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# you need to use only a subset here. The full set is REALLY SLOW for debugging...\n",
    "size = 2000\n",
    "x_train_images = x_train_images_[:size, :, :, :]\n",
    "x_test_images = x_test_images_[:size, :, :, :]\n",
    "y_train = y_train_[:size]\n",
    "y_test = y_test_[:size]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "y_train[y_train > 2] = 3\n",
    "y_test[y_test > 2] = 3"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "y_train = y_train.astype('int')\n",
    "y_test = y_test.astype('int')\n",
    "print(np.unique(y_train, return_counts=True)[1]/len(y_train))\n",
    "print(np.unique(y_test, return_counts=True)[1]/len(y_test))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Transform & Visualization\n",
    "Two ways to transform. \\\n",
    "1) Potentially use the torchvision.transforms. However, then you have to iteratre over each image with PIL Image. It can be very slow. \n",
    "2) Customize the transformation by yourself in numpy...\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# specify data type. \n",
    "x_train_images=x_train_images.astype(\"float32\")\n",
    "x_test_images=x_test_images.astype(\"float32\")\n",
    "y_train=y_train.astype(\"int\")\n",
    "y_test=y_test.astype(\"int\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# transform.\n",
    "# normalize to [0,1]\n",
    "x_train_images_norm = x_train_images/255\n",
    "x_test_images_norm = x_test_images/255\n",
    "\n",
    "# to torch\n",
    "x_train_torch = torch.from_numpy(x_train_images_norm)\n",
    "x_test_torch = torch.from_numpy(x_test_images_norm)\n",
    "y_train_torch = torch.from_numpy(y_train)\n",
    "y_test_torch = torch.from_numpy(y_test)\n",
    "\n",
    "print(x_train_torch.size())\n",
    "print(x_test_torch.size())\n",
    "print(y_train_torch.size())\n",
    "print(y_test_torch.size())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# use data loader: train and test. \n",
    "train_ds = TensorDataset(x_train_torch, y_train_torch)\n",
    "batch_size = 200\n",
    "train_dl = DataLoader(train_ds, batch_size, shuffle = True)\n",
    "\n",
    "test_ds = TensorDataset(x_test_torch, y_test_torch)\n",
    "batch_size = 200\n",
    "test_dl = DataLoader(test_ds, batch_size, shuffle = True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "# visualize with torchvision.\n",
    "images_, labels_ = iter(train_dl).next()\n",
    "images = images_[:5,] # visualize five images\n",
    "labels = labels_[:5] # visualize five images\n",
    "\n",
    "def imshow(img):\n",
    "#     img = img * 255.0     # unnormalize\n",
    "    npimg = img.numpy()\n",
    "    plt.figure(figsize = (15,3))\n",
    "    plt.imshow(np.transpose(npimg, (1, 2, 0)))\n",
    "    plt.show()\n",
    "    \n",
    "imshow(torchvision.utils.make_grid(images))\n",
    "print(labels.numpy())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 1. Use naive CNN model\n",
    "class Net(nn.Module):\n",
    "    # sw: again. It is critical to understand the dimension transformation.\n",
    "    def __init__(self):\n",
    "        super(Net, self).__init__()\n",
    "        self.conv1 = nn.Conv2d(3, 6, 5) # sw: change the input channel for data set.\n",
    "        self.pool = nn.MaxPool2d(2, 2)\n",
    "        self.conv2 = nn.Conv2d(6, 16, 5)\n",
    "        self.fc1 = nn.Linear(16 * 47 * 47, 120)\n",
    "        self.fc2 = nn.Linear(120, 84)\n",
    "        self.fc3 = nn.Linear(84, 4)\n",
    "\n",
    "    def forward(self, x):\n",
    "        x = self.pool(F.relu(self.conv1(x)))\n",
    "        x = self.pool(F.relu(self.conv2(x)))\n",
    "        x = x.view(-1, 16 * 47 * 47)\n",
    "        x = F.relu(self.fc1(x))\n",
    "        x = F.relu(self.fc2(x))\n",
    "        x = self.fc3(x)\n",
    "        return x\n",
    "\n",
    "# initialize\n",
    "net = Net().float().to(device)\n",
    "\n",
    "# # test\n",
    "# images, labels = iter(train_dl).next()\n",
    "# output = net(images)\n",
    "# print(output.size())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 2. Use ResNet.\n",
    "model_ft = models.resnet18(pretrained=False)\n",
    "for param in model_ft.parameters():\n",
    "    param.requires_grad = True # Shenhao might change it to True. Train the full set.\n",
    "\n",
    "# The following line allows us to edit the input channels.\n",
    "# model_ft.conv1 = nn.Conv2d(4, 64, kernel_size=(7, 7), stride=(2, 2), padding=(3, 3), bias=False)    \n",
    "num_ftrs = model_ft.fc.in_features\n",
    "model_ft.fc = nn.Linear(num_ftrs, 4)\n",
    "net = model_ft.to(device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch.optim as optim\n",
    "\n",
    "criterion = nn.CrossEntropyLoss()\n",
    "optimizer = optim.SGD(net.parameters(), lr=0.001, momentum=0.9)\n",
    "n_epoch = 100"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "for epoch in range(n_epoch):# loop over the dataset multiple times\n",
    "    # sw: learn the way of printing out the total loss for each batch.\n",
    "    running_loss_train = 0.0\n",
    "    running_loss_test = 0.0\n",
    "    correct_train = 0\n",
    "    total_train = 0\n",
    "    correct_test = 0\n",
    "    total_test = 0\n",
    "    \n",
    "    # training    \n",
    "    for inputs, labels in train_dl:\n",
    "        # to device\n",
    "        inputs = inputs.to(device)\n",
    "        labels = labels.to(device)\n",
    "\n",
    "        # forward + backward\n",
    "        outputs = net(inputs)\n",
    "        loss = criterion(outputs, labels)\n",
    "        loss.backward()\n",
    "        \n",
    "        # evaluate prediction\n",
    "        _, predicted = torch.max(outputs.data, 1)\n",
    "        total_train += labels.size(0)\n",
    "        correct_train += (predicted == labels).sum().item()\n",
    "        \n",
    "        # optimize\n",
    "        optimizer.step()\n",
    "        optimizer.zero_grad()\n",
    "        \n",
    "        # statistics\n",
    "        running_loss_train += loss.item()\n",
    "        \n",
    "    # testing\n",
    "    for inputs, labels in test_dl:\n",
    "        # to device\n",
    "        inputs = inputs.to(device)\n",
    "        labels = labels.to(device)\n",
    "        outputs = net(inputs)\n",
    "        loss = criterion(outputs, labels)\n",
    "        running_loss_test += loss.item()\n",
    "        \n",
    "        # evaluate prediction\n",
    "        _, predicted = torch.max(outputs.data, 1)\n",
    "        total_test += labels.size(0)\n",
    "        correct_test += (predicted == labels).sum().item()\n",
    "        \n",
    "    print(\"Epoch {}: Training Loss {}; Testing Loss {}\".format(epoch, running_loss_train, running_loss_test))\n",
    "    print(\"Epoch {}: Training Accuracy {}; Testing Accuracy {}\".format(epoch, correct_train/total_train, correct_test/total_test))\n",
    "\n",
    "#         if i % 2000 == 1999:    # print every 2000 mini-batches\n",
    "#             print('[%d, %5d] loss: %.3f' %\n",
    "#                   (epoch + 1, i + 1, running_loss / 2000))\n",
    "#             running_loss = 0.0\n",
    "# print('Finished Training')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
