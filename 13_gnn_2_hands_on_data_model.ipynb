{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "# tutorial from: https://towardsdatascience.com/hands-on-graph-neural-networks-with-pytorch-pytorch-geometric-359487e221a8\n",
    "# https://github.com/khuangaf/PyTorch-Geometric-YooChoose\n",
    "# \n",
    "# "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import torch\n",
    "from torch_geometric.data import Data"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Part 1 - Naive application"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# node inputs and outputs\n",
    "x = torch.tensor([[2,1], [5,6], [3,7], [12,0]], dtype=torch.float)\n",
    "y = torch.tensor([0, 1, 0, 1], dtype=torch.float)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# define links in a graph.\n",
    "# directed graph from source to target nodes! \n",
    "edge_index = torch.tensor([[0, 1, 2, 0, 3],\n",
    "                           [1, 0, 1, 3, 2]], dtype=torch.long)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Data(edge_index=[2, 5], x=[4, 2], y=[4])"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# create the graph data\n",
    "# sw: I learnt the basic format to prepare the data set.\n",
    "data = Data(x=x, y=y, edge_index=edge_index)\n",
    "data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "# note: InMemoryDataset vs. Dataset.\n",
    "# It depends on the size of the data sets. \n",
    "# Q: How is the batch even possible? \n",
    "# Q: How to reconcile the global computing in basic GCN and the batch thing (local)?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "# # read winzip and extract files\n",
    "# import py7zr\n",
    "# archive = py7zr.SevenZipFile('./data_shenhao/graph_choose_buy/yoochoose-data.7z', mode='r')\n",
    "# archive.extractall(path=\"./data_shenhao/graph_choose_buy/\")\n",
    "# archive.close()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Part 2. graph data preparation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.preprocessing import LabelEncoder"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/jtl/anaconda3/lib/python3.7/site-packages/IPython/core/interactiveshell.py:3072: DtypeWarning: Columns (3) have mixed types.Specify dtype option on import or set low_memory=False.\n",
      "  interactivity=interactivity, compiler=compiler, result=result)\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>session_id</th>\n",
       "      <th>timestamp</th>\n",
       "      <th>item_id</th>\n",
       "      <th>category</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1</td>\n",
       "      <td>2014-04-07T10:51:09.277Z</td>\n",
       "      <td>214536502</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1</td>\n",
       "      <td>2014-04-07T10:54:09.868Z</td>\n",
       "      <td>214536500</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>1</td>\n",
       "      <td>2014-04-07T10:54:46.998Z</td>\n",
       "      <td>214536506</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>1</td>\n",
       "      <td>2014-04-07T10:57:00.306Z</td>\n",
       "      <td>214577561</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>2</td>\n",
       "      <td>2014-04-07T13:56:37.614Z</td>\n",
       "      <td>214662742</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   session_id                 timestamp    item_id category\n",
       "0           1  2014-04-07T10:51:09.277Z  214536502        0\n",
       "1           1  2014-04-07T10:54:09.868Z  214536500        0\n",
       "2           1  2014-04-07T10:54:46.998Z  214536506        0\n",
       "3           1  2014-04-07T10:57:00.306Z  214577561        0\n",
       "4           2  2014-04-07T13:56:37.614Z  214662742        0"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# read files\n",
    "# sw: the basic data set is very similar to many travel data sets. \n",
    "df = pd.read_csv('./data_shenhao/graph_choose_buy/yoochoose-clicks.dat', header=None)\n",
    "df.columns=['session_id','timestamp','item_id','category']\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "# \n",
    "buy_df = pd.read_csv('./data_shenhao/graph_choose_buy/yoochoose-buys.dat', header=None)\n",
    "buy_df.columns=['session_id','timestamp','item_id','price','quantity']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>session_id</th>\n",
       "      <th>timestamp</th>\n",
       "      <th>item_id</th>\n",
       "      <th>category</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1</td>\n",
       "      <td>2014-04-07T10:51:09.277Z</td>\n",
       "      <td>2053</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1</td>\n",
       "      <td>2014-04-07T10:54:09.868Z</td>\n",
       "      <td>2052</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>1</td>\n",
       "      <td>2014-04-07T10:54:46.998Z</td>\n",
       "      <td>2054</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>1</td>\n",
       "      <td>2014-04-07T10:57:00.306Z</td>\n",
       "      <td>9876</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>2</td>\n",
       "      <td>2014-04-07T13:56:37.614Z</td>\n",
       "      <td>19448</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   session_id                 timestamp  item_id category\n",
       "0           1  2014-04-07T10:51:09.277Z     2053        0\n",
       "1           1  2014-04-07T10:54:09.868Z     2052        0\n",
       "2           1  2014-04-07T10:54:46.998Z     2054        0\n",
       "3           1  2014-04-07T10:57:00.306Z     9876        0\n",
       "4           2  2014-04-07T13:56:37.614Z    19448        0"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# \n",
    "item_encoder = LabelEncoder() # Q: What is this fun? A: transform the discrete values to 0~N.\n",
    "df['item_id'] = item_encoder.fit_transform(df.item_id)\n",
    "df.head()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "session_id    100000\n",
       "timestamp     356209\n",
       "item_id        20523\n",
       "category         111\n",
       "dtype: int64"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# randomly sample a couple of them\n",
    "sampled_session_id = np.random.choice(df.session_id.unique(), 100000, replace=False)\n",
    "df = df.loc[df.session_id.isin(sampled_session_id)] # sw: good indexing function. \n",
    "df.nunique() # sw: good summary report function."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>session_id</th>\n",
       "      <th>timestamp</th>\n",
       "      <th>item_id</th>\n",
       "      <th>category</th>\n",
       "      <th>label</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>198</th>\n",
       "      <td>62</td>\n",
       "      <td>2014-04-06T15:42:34.618Z</td>\n",
       "      <td>28438</td>\n",
       "      <td>0</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>199</th>\n",
       "      <td>62</td>\n",
       "      <td>2014-04-06T15:43:00.299Z</td>\n",
       "      <td>12957</td>\n",
       "      <td>0</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>200</th>\n",
       "      <td>62</td>\n",
       "      <td>2014-04-06T15:44:51.971Z</td>\n",
       "      <td>41158</td>\n",
       "      <td>0</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>201</th>\n",
       "      <td>62</td>\n",
       "      <td>2014-04-06T15:45:44.613Z</td>\n",
       "      <td>31369</td>\n",
       "      <td>0</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>202</th>\n",
       "      <td>62</td>\n",
       "      <td>2014-04-06T15:45:49.462Z</td>\n",
       "      <td>39937</td>\n",
       "      <td>0</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>203</th>\n",
       "      <td>62</td>\n",
       "      <td>2014-04-06T15:46:27.323Z</td>\n",
       "      <td>29199</td>\n",
       "      <td>0</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>204</th>\n",
       "      <td>62</td>\n",
       "      <td>2014-04-06T15:46:47.147Z</td>\n",
       "      <td>41270</td>\n",
       "      <td>0</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>205</th>\n",
       "      <td>62</td>\n",
       "      <td>2014-04-06T15:47:14.526Z</td>\n",
       "      <td>31812</td>\n",
       "      <td>0</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>206</th>\n",
       "      <td>62</td>\n",
       "      <td>2014-04-06T15:48:36.052Z</td>\n",
       "      <td>41262</td>\n",
       "      <td>0</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>207</th>\n",
       "      <td>62</td>\n",
       "      <td>2014-04-06T15:48:56.201Z</td>\n",
       "      <td>37075</td>\n",
       "      <td>0</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>432</th>\n",
       "      <td>138</td>\n",
       "      <td>2014-04-04T08:59:39.071Z</td>\n",
       "      <td>12217</td>\n",
       "      <td>0</td>\n",
       "      <td>True</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>433</th>\n",
       "      <td>138</td>\n",
       "      <td>2014-04-04T09:05:08.905Z</td>\n",
       "      <td>12200</td>\n",
       "      <td>0</td>\n",
       "      <td>True</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>434</th>\n",
       "      <td>138</td>\n",
       "      <td>2014-04-04T09:22:48.742Z</td>\n",
       "      <td>12859</td>\n",
       "      <td>0</td>\n",
       "      <td>True</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>435</th>\n",
       "      <td>138</td>\n",
       "      <td>2014-04-04T09:24:15.178Z</td>\n",
       "      <td>12859</td>\n",
       "      <td>0</td>\n",
       "      <td>True</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>436</th>\n",
       "      <td>138</td>\n",
       "      <td>2014-04-04T09:24:47.588Z</td>\n",
       "      <td>12861</td>\n",
       "      <td>0</td>\n",
       "      <td>True</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "     session_id                 timestamp  item_id category  label\n",
       "198          62  2014-04-06T15:42:34.618Z    28438        0  False\n",
       "199          62  2014-04-06T15:43:00.299Z    12957        0  False\n",
       "200          62  2014-04-06T15:44:51.971Z    41158        0  False\n",
       "201          62  2014-04-06T15:45:44.613Z    31369        0  False\n",
       "202          62  2014-04-06T15:45:49.462Z    39937        0  False\n",
       "203          62  2014-04-06T15:46:27.323Z    29199        0  False\n",
       "204          62  2014-04-06T15:46:47.147Z    41270        0  False\n",
       "205          62  2014-04-06T15:47:14.526Z    31812        0  False\n",
       "206          62  2014-04-06T15:48:36.052Z    41262        0  False\n",
       "207          62  2014-04-06T15:48:56.201Z    37075        0  False\n",
       "432         138  2014-04-04T08:59:39.071Z    12217        0   True\n",
       "433         138  2014-04-04T09:05:08.905Z    12200        0   True\n",
       "434         138  2014-04-04T09:22:48.742Z    12859        0   True\n",
       "435         138  2014-04-04T09:24:15.178Z    12859        0   True\n",
       "436         138  2014-04-04T09:24:47.588Z    12861        0   True"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Check if clicks lead to buy\n",
    "# sw: imagine it is the relationship between travel activities and travel modes. \n",
    "df['label'] = df.session_id.isin(buy_df.session_id)\n",
    "df.head(15)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "from torch_geometric.data import InMemoryDataset\n",
    "from tqdm import tqdm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [],
   "source": [
    "# To-Be read carefully...\n",
    "\n",
    "class YooChooseBinaryDataset(InMemoryDataset):\n",
    "    def __init__(self, root, transform=None, pre_transform=None):\n",
    "        super(YooChooseBinaryDataset, self).__init__(root, transform, pre_transform)\n",
    "        self.data, self.slices = torch.load(self.processed_paths[0]) \n",
    "        # sw Q: what is this processed_paths[0]? \n",
    "        # sw A: it inherits from InMemoryDataset and Dataset object. We skip data processing if the processed_file_names already exists.\n",
    "\n",
    "    @property\n",
    "    def raw_file_names(self):\n",
    "        return []\n",
    "    \n",
    "    @property\n",
    "    def processed_file_names(self):\n",
    "        return ['yoochoose_click_binary_1M_sess.dataset']\n",
    "\n",
    "    def download(self):\n",
    "        pass\n",
    "    \n",
    "    def process(self): \n",
    "        # sw: data is processed here and automatically saved into a folder called processed.\n",
    "        data_list = []\n",
    "\n",
    "        # process by session_id\n",
    "        grouped = df.groupby('session_id')\n",
    "        \n",
    "        for session_id, group in tqdm(grouped): # sw: tqdm amazing tool to iterate over the grouped object! \n",
    "            sess_item_id = LabelEncoder().fit_transform(group.item_id)\n",
    "            group = group.reset_index(drop=True)\n",
    "            group['sess_item_id'] = sess_item_id\n",
    "            node_features = group.loc[group.session_id==session_id,['sess_item_id','item_id']].sort_values('sess_item_id').item_id.drop_duplicates().values\n",
    "\n",
    "            node_features = torch.LongTensor(node_features).unsqueeze(1)\n",
    "            target_nodes = group.sess_item_id.values[1:]\n",
    "            source_nodes = group.sess_item_id.values[:-1]\n",
    "\n",
    "            edge_index = torch.tensor([source_nodes, target_nodes], dtype=torch.long)\n",
    "            x = node_features\n",
    "\n",
    "            y = torch.FloatTensor([group.label.values[0]])\n",
    "\n",
    "            data = Data(x=x, edge_index=edge_index, y=y)\n",
    "            data_list.append(data) # sw: a list of graphs. The authors reduce the sessions into many graphs.\n",
    "        \n",
    "        data, slices = self.collate(data_list) # sw: unclear about the purpose of the function - but always add it!\n",
    "        torch.save((data, slices), self.processed_paths[0])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  0%|          | 0/100000 [00:00<?, ?it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Initial session id is 62\n",
      "Show an individual group in the groupby obj      session_id                 timestamp  item_id category  label\n",
      "198          62  2014-04-06T15:42:34.618Z    28438        0  False\n",
      "199          62  2014-04-06T15:43:00.299Z    12957        0  False\n",
      "200          62  2014-04-06T15:44:51.971Z    41158        0  False\n",
      "201          62  2014-04-06T15:45:44.613Z    31369        0  False\n",
      "202          62  2014-04-06T15:45:49.462Z    39937        0  False\n",
      "203          62  2014-04-06T15:46:27.323Z    29199        0  False\n",
      "204          62  2014-04-06T15:46:47.147Z    41270        0  False\n",
      "205          62  2014-04-06T15:47:14.526Z    31812        0  False\n",
      "206          62  2014-04-06T15:48:36.052Z    41262        0  False\n",
      "207          62  2014-04-06T15:48:56.201Z    37075        0  False\n",
      "Fit transformed item id is [1 0 7 3 6 2 9 4 8 5]\n",
      "reindexed group\n",
      "   session_id                 timestamp  item_id category  label\n",
      "0          62  2014-04-06T15:42:34.618Z    28438        0  False\n",
      "1          62  2014-04-06T15:43:00.299Z    12957        0  False\n",
      "2          62  2014-04-06T15:44:51.971Z    41158        0  False\n",
      "3          62  2014-04-06T15:45:44.613Z    31369        0  False\n",
      "4          62  2014-04-06T15:45:49.462Z    39937        0  False\n",
      "5          62  2014-04-06T15:46:27.323Z    29199        0  False\n",
      "6          62  2014-04-06T15:46:47.147Z    41270        0  False\n",
      "7          62  2014-04-06T15:47:14.526Z    31812        0  False\n",
      "8          62  2014-04-06T15:48:36.052Z    41262        0  False\n",
      "9          62  2014-04-06T15:48:56.201Z    37075        0  False\n",
      "node features are [12957 28438 29199 31369 31812 37075 39937 41158 41262 41270]\n",
      "node features are tensor([[12957],\n",
      "        [28438],\n",
      "        [29199],\n",
      "        [31369],\n",
      "        [31812],\n",
      "        [37075],\n",
      "        [39937],\n",
      "        [41158],\n",
      "        [41262],\n",
      "        [41270]])\n",
      "targeting nodes are  [0 7 3 6 2 9 4 8 5]\n",
      "source nodes are  [1 0 7 3 6 2 9 4 8]\n",
      "edge index are tensor([[1, 0, 7, 3, 6, 2, 9, 4, 8],\n",
      "        [0, 7, 3, 6, 2, 9, 4, 8, 5]])\n",
      "Final node features are the item IDs tensor([[12957],\n",
      "        [28438],\n",
      "        [29199],\n",
      "        [31369],\n",
      "        [31812],\n",
      "        [37075],\n",
      "        [39937],\n",
      "        [41158],\n",
      "        [41262],\n",
      "        [41270]])\n",
      "False\n",
      "Final targeting variable is tensor([0.])\n",
      "One block of data looks like: Data(edge_index=[2, 9], x=[10, 1], y=[1])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "# sw analyzes the block above. Very INFORMATIVE.\n",
    "grouped = df.groupby('session_id')\n",
    "for session_id, group in tqdm(grouped):\n",
    "    break\n",
    "print(\"Initial session id is {}\".format(session_id))\n",
    "print(\"Show an individual group in the groupby obj\", group)\n",
    "\n",
    "sess_item_id = LabelEncoder().fit_transform(group.item_id)\n",
    "print(\"Fit transformed item id is {}\".format(sess_item_id))\n",
    "\n",
    "group = group.reset_index(drop=True)\n",
    "print(\"reindexed group\")\n",
    "print(group)\n",
    "\n",
    "group['sess_item_id'] = sess_item_id\n",
    "\n",
    "node_features = group.loc[group.session_id==session_id,['sess_item_id','item_id']].sort_values('sess_item_id').item_id.drop_duplicates().values\n",
    "print(\"node features are\", node_features) # sw: wait the node_features are the item id...\n",
    "\n",
    "node_features = torch.LongTensor(node_features).unsqueeze(1)\n",
    "print(\"node features are\", node_features) # sw: adjust the node features' dim - N * 1.\n",
    "\n",
    "target_nodes = group.sess_item_id.values[1:]\n",
    "source_nodes = group.sess_item_id.values[:-1]\n",
    "print(\"targeting nodes are \", target_nodes)\n",
    "print(\"source nodes are \", source_nodes)\n",
    "\n",
    "edge_index = torch.tensor([source_nodes, target_nodes], dtype=torch.long)\n",
    "print(\"edge index are\", edge_index) # sw: note that the edge indicators are dif from node item indicators. \n",
    "\n",
    "x = node_features\n",
    "print(\"Final node features are the item IDs {}\".format(x))\n",
    "\n",
    "y = torch.FloatTensor([group.label.values[0]])\n",
    "print(group.label.values[0])\n",
    "print(\"Final targeting variable is {}\".format(y))\n",
    "\n",
    "data = Data(x=x, edge_index=edge_index, y=y)\n",
    "print(\"One block of data looks like:\", data)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "dataset = YooChooseBinaryDataset('./data_shenhao/graph_choose_buy/') # sw: this is the root dir for data processing. \n",
    "#! First run costs 30 min"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(80000, 10000, 10000)"
      ]
     },
     "execution_count": 40,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dataset = dataset.shuffle()\n",
    "train_dataset = dataset[:80000]\n",
    "val_dataset = dataset[80000:90000]\n",
    "test_dataset = dataset[90000:]\n",
    "len(train_dataset), len(val_dataset), len(test_dataset)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [],
   "source": [
    "from torch_geometric.data import DataLoader\n",
    "batch_size= 1024\n",
    "train_loader = DataLoader(train_dataset, batch_size=batch_size)\n",
    "val_loader = DataLoader(val_dataset, batch_size=batch_size)\n",
    "test_loader = DataLoader(test_dataset, batch_size=batch_size)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "52707"
      ]
     },
     "execution_count": 42,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "num_items = df.item_id.max() +1 # return the total number of items.\n",
    "num_items"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Batch(batch=[2890], edge_index=[2, 2481], x=[2890, 1], y=[1024])\n",
      "tensor([   0,    0,    0,  ..., 1022, 1023, 1023])\n",
      "tensor([[   3,    2,    1,  ..., 2885, 2887, 2889],\n",
      "        [   2,    1,    2,  ..., 2885, 2887, 2888]])\n",
      "tensor([[  420],\n",
      "        [ 2287],\n",
      "        [20230],\n",
      "        ...,\n",
      "        [14040],\n",
      "        [41981],\n",
      "        [47208]])\n",
      "tensor([0., 0., 0.,  ..., 0., 0., 0.])\n"
     ]
    }
   ],
   "source": [
    "# sw: analyze the data structure in data loader\n",
    "# sw: train_loader has many IID graphs. Each graph has node attributes, edge attributes, edge index, etc.\n",
    "\n",
    "for data in train_loader:\n",
    "    d = data\n",
    "    break\n",
    "\n",
    "print(d)\n",
    "print(d.batch)\n",
    "print(d.edge_index)\n",
    "print(d.x)\n",
    "print(d.y)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "from torch.nn import Sequential as Seq, Linear, ReLU\n",
    "from torch_geometric.nn import MessagePassing\n",
    "from torch_geometric.utils import remove_self_loops, add_self_loops\n",
    "class SAGEConv(MessagePassing):\n",
    "    def __init__(self, in_channels, out_channels):\n",
    "        super(SAGEConv, self).__init__(aggr='max') #  \"Max\" aggregation.\n",
    "        self.lin = torch.nn.Linear(in_channels, out_channels)\n",
    "        self.act = torch.nn.ReLU()\n",
    "        self.update_lin = torch.nn.Linear(in_channels + out_channels, in_channels, bias=False)\n",
    "        self.update_act = torch.nn.ReLU()\n",
    "        \n",
    "    def forward(self, x, edge_index):\n",
    "        # x has shape [N, in_channels]\n",
    "        # edge_index has shape [2, E]\n",
    "        \n",
    "        \n",
    "        edge_index, _ = remove_self_loops(edge_index)\n",
    "        edge_index, _ = add_self_loops(edge_index, num_nodes=x.size(0))\n",
    "        \n",
    "        \n",
    "        return self.propagate(edge_index, size=(x.size(0), x.size(0)), x=x)\n",
    "\n",
    "    def message(self, x_j):\n",
    "        # x_j has shape [E, in_channels]\n",
    "\n",
    "        x_j = self.lin(x_j)\n",
    "        x_j = self.act(x_j)\n",
    "        \n",
    "        return x_j\n",
    "\n",
    "    def update(self, aggr_out, x):\n",
    "        # aggr_out has shape [N, out_channels]\n",
    "\n",
    "\n",
    "        new_embedding = torch.cat([aggr_out, x], dim=1)\n",
    "        \n",
    "        new_embedding = self.update_lin(new_embedding)\n",
    "        new_embedding = self.update_act(new_embedding)\n",
    "        \n",
    "        return new_embedding"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [],
   "source": [
    "embed_dim = 128\n",
    "from torch_geometric.nn import GraphConv, TopKPooling, GatedGraphConv\n",
    "from torch_geometric.nn import global_mean_pool as gap, global_max_pool as gmp\n",
    "import torch.nn.functional as F\n",
    "class Net(torch.nn.Module):\n",
    "    def __init__(self):\n",
    "        super(Net, self).__init__()\n",
    "\n",
    "        self.conv1 = SAGEConv(embed_dim, 128)\n",
    "        self.pool1 = TopKPooling(128, ratio=0.8)\n",
    "        self.conv2 = SAGEConv(128, 128)\n",
    "        self.pool2 = TopKPooling(128, ratio=0.8)\n",
    "        self.conv3 = SAGEConv(128, 128)\n",
    "        self.pool3 = TopKPooling(128, ratio=0.8)\n",
    "        self.item_embedding = torch.nn.Embedding(num_embeddings=df.item_id.max() +1, embedding_dim=embed_dim)\n",
    "        self.lin1 = torch.nn.Linear(256, 128)\n",
    "        self.lin2 = torch.nn.Linear(128, 64)\n",
    "        self.lin3 = torch.nn.Linear(64, 1)\n",
    "        self.bn1 = torch.nn.BatchNorm1d(128)\n",
    "        self.bn2 = torch.nn.BatchNorm1d(64)\n",
    "        self.act1 = torch.nn.ReLU()\n",
    "        self.act2 = torch.nn.ReLU()        \n",
    "  \n",
    "    def forward(self, data):\n",
    "        x, edge_index, batch = data.x, data.edge_index, data.batch\n",
    "        x = self.item_embedding(x)\n",
    "        x = x.squeeze(1)        \n",
    "\n",
    "        x = F.relu(self.conv1(x, edge_index))\n",
    "\n",
    "        x, edge_index, _, batch, _, _ = self.pool1(x, edge_index, None, batch)\n",
    "        x1 = torch.cat([gmp(x, batch), gap(x, batch)], dim=1)\n",
    "\n",
    "        x = F.relu(self.conv2(x, edge_index))\n",
    "     \n",
    "        x, edge_index, _, batch, _, _ = self.pool2(x, edge_index, None, batch)\n",
    "        x2 = torch.cat([gmp(x, batch), gap(x, batch)], dim=1)\n",
    "\n",
    "        x = F.relu(self.conv3(x, edge_index))\n",
    "\n",
    "        x, edge_index, _, batch, _, _ = self.pool3(x, edge_index, None, batch)\n",
    "        x3 = torch.cat([gmp(x, batch), gap(x, batch)], dim=1)\n",
    "\n",
    "        x = x1 + x2 + x3\n",
    "\n",
    "        x = self.lin1(x)\n",
    "        x = self.act1(x)\n",
    "        x = self.lin2(x)\n",
    "        x = self.act2(x)      \n",
    "        x = F.dropout(x, p=0.5, training=self.training)\n",
    "\n",
    "        x = torch.sigmoid(self.lin3(x)).squeeze(1)\n",
    "\n",
    "        return x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [],
   "source": [
    "device = torch.device('cuda:0')\n",
    "model = Net().to(device)\n",
    "optimizer = torch.optim.Adam(model.parameters(), lr=0.005)\n",
    "crit = torch.nn.BCELoss()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [],
   "source": [
    "def train():\n",
    "    model.train()\n",
    "\n",
    "    loss_all = 0\n",
    "    for data in train_loader:\n",
    "        data = data.to(device)\n",
    "        optimizer.zero_grad()\n",
    "        output = model(data)\n",
    "        label = data.y.to(device)\n",
    "        loss = crit(output, label)\n",
    "        loss.backward()\n",
    "        loss_all += data.num_graphs * loss.item()\n",
    "        optimizer.step()\n",
    "    return loss_all / len(train_dataset)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.metrics import roc_auc_score\n",
    "def evaluate(loader):\n",
    "    model.eval()\n",
    "\n",
    "    predictions = []\n",
    "    labels = []\n",
    "\n",
    "    with torch.no_grad():\n",
    "        for data in loader:\n",
    "\n",
    "            data = data.to(device)\n",
    "            pred = model(data).detach().cpu().numpy()\n",
    "\n",
    "            label = data.y.detach().cpu().numpy()\n",
    "            predictions.append(pred)\n",
    "            labels.append(label)\n",
    "\n",
    "    predictions = np.hstack(predictions)\n",
    "    labels = np.hstack(labels)\n",
    "    \n",
    "    return roc_auc_score(labels, predictions)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 000, Loss: 0.19731, Train Auc: 0.83172, Val Auc: 0.66619, Test Auc: 0.65998\n",
      "Epoch: 001, Loss: 0.17814, Train Auc: 0.86945, Val Auc: 0.65645, Test Auc: 0.64241\n",
      "Epoch: 002, Loss: 0.15777, Train Auc: 0.88363, Val Auc: 0.65822, Test Auc: 0.64234\n"
     ]
    }
   ],
   "source": [
    "for epoch in range(3):\n",
    "    loss = train()\n",
    "    train_acc = evaluate(train_loader)\n",
    "    val_acc = evaluate(val_loader)    \n",
    "    test_acc = evaluate(test_loader)\n",
    "    print('Epoch: {:03d}, Loss: {:.5f}, Train Auc: {:.5f}, Val Auc: {:.5f}, Test Auc: {:.5f}'.\n",
    "          format(epoch, loss, train_acc, val_acc, test_acc))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "ename": "ValueError",
     "evalue": "attempted relative import beyond top-level package",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mValueError\u001b[0m                             Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-8-8b73ff8837c4>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m      4\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mpandas\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0mpd\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      5\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 6\u001b[0;31m \u001b[0;32mfrom\u001b[0m \u001b[0;34m.\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdatasets\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdataset_base\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mDatasetBase\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      7\u001b[0m from ..utils.constants import (\n\u001b[1;32m      8\u001b[0m     \u001b[0mDEFAULT_ITEM_COL\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mValueError\u001b[0m: attempted relative import beyond top-level package"
     ]
    }
   ],
   "source": [
    "import csv\n",
    "import os\n",
    "\n",
    "import pandas as pd\n",
    "\n",
    "from ..datasets.dataset_base import DatasetBase\n",
    "from ..utils.constants import (\n",
    "    DEFAULT_ITEM_COL,\n",
    "    DEFAULT_RATING_COL,\n",
    "    DEFAULT_TIMESTAMP_COL,\n",
    "    DEFAULT_USER_COL,\n",
    ")\n",
    "\n",
    "# Download URL\n",
    "YOOCHOOSE_URL = \"https://s3-eu-west-1.amazonaws.com/yc-rdata/yoochoose-data.7z\"\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
